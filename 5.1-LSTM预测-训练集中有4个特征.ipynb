{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import gamma\n",
    "\n",
    "df = pd.read_csv(\"order_train1.csv\", encoding=\"gbk\")\n",
    "df[\"order_date\"]=df[\"order_date\"].apply(pd.to_datetime,format='%Y-%m-%d')\n",
    "# data.drop('order_date', axis=1, inplace=True)\n",
    "\n",
    "df = df.set_index('order_date')\n",
    "df_train = df[['sales_region_code', 'first_cate_code','second_cate_code','item_code','ord_qty']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre = pd.read_csv(\"pred-you-4.csv\", encoding=\"gbk\")\n",
    "## 查看预测数据\n",
    "data_pre = pd.DataFrame(pre,columns=['sales_region_code', 'item_code','first_cate_code', 'second_cate_code',])\n",
    "# groupby(['sales_region_code'])['ord_qty'].sum().sort_values()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练集中有4个特征"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train1 = df_train[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "df_train1 = df_train1.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.losses import mean_squared_error\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 指定 EarlyStopping 回调函数\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "predictions_df = pd.DataFrame(columns=['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code', ])\n",
    "\n",
    "# Loop over all sales_region_code and item_code combinations\n",
    "for i in range(len(data_pre)):\n",
    "    sales_region_code, item_code, first_cate_code, second_cate_code = data_pre.iloc[i, :]\n",
    "    # print(sales_region_code, item_code, first_cate_code, second_cate_code)\n",
    "    # print(sales_region_code, item_code, first_cate_code, second_cate_code)\n",
    "    if len(df_train[(df_train['sales_region_code'] == sales_region_code) & (df_train['item_code'] == item_code) & (df_train['first_cate_code'] == first_cate_code) & (df_train['second_cate_code'] == second_cate_code)])>0:\n",
    "        filtered_df = df_train[(df_train['sales_region_code'] == sales_region_code) & (df_train['item_code'] == item_code) & (df_train['first_cate_code'] == first_cate_code) & (df_train['second_cate_code'] == second_cate_code)]\n",
    "        # print(filtered_df)\n",
    "        filtered_df_byday = filtered_df.groupby([pd.Grouper(freq='D')])['ord_qty'].mean().reset_index()\n",
    "        filtered_df_byday.set_index('order_date',inplace = True)\n",
    "        filtered_df_byday = filtered_df_byday.fillna(method='ffill')\n",
    "        # print(filtered_df)\n",
    "        values = filtered_df_byday['ord_qty'].values.reshape(-1,1)\n",
    "        # print(values.shape)\n",
    "        # print(values.shape[0])\n",
    "        # print(values.shape[1])\n",
    "\n",
    "        if values.shape[0]>0:\n",
    "\n",
    "            # values.to_numpy(values)\n",
    "            values = values.astype('float32')\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            scaled = scaler.fit_transform(values)\n",
    "            train_size = int(len(scaled) * 0.8)\n",
    "            test_size = len(scaled) - train_size\n",
    "            train, test = scaled[0:train_size,:], scaled[train_size:len(scaled),:]\n",
    "            # print(test.shape)\n",
    "\n",
    "            if test_size > 1:\n",
    "\n",
    "                if test_size>30:\n",
    "                    look_back = 30\n",
    "                    print('>30', item_code, sales_region_code,first_cate_code, second_cate_code)\n",
    "                    X_train, y_train = create_dataset(train, look_back)\n",
    "                    X_test, y_test = create_dataset(test, look_back)\n",
    "\n",
    "                if 30 >= test_size > 1:\n",
    "                    print('1-30', item_code, sales_region_code,first_cate_code, second_cate_code)\n",
    "                    look_back = test_size-1\n",
    "                    X_train, y_train = create_dataset(train, look_back)\n",
    "                    X_test, y_test = create_dataset(test, look_back)\n",
    "\n",
    "\n",
    "                X_train, y_train = create_dataset(train, look_back)\n",
    "                X_test, y_test = create_dataset(test, look_back)\n",
    "                # print(X_train.shape)\n",
    "                # print(X_test.shape)\n",
    "\n",
    "                X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "                X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "                # Check if there is enough data to make a prediction\n",
    "                # 指定 EarlyStopping 回调函数\n",
    "                early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
    "                if len(X_test) > 0:\n",
    "                    # Create the RNN model\n",
    "                    model = tf.keras.Sequential([\n",
    "                    tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "                    tf.keras.layers.Dropout(0.2),\n",
    "                    tf.keras.layers.LSTM(32),\n",
    "                    tf.keras.layers.Dropout(0.2),\n",
    "                    tf.keras.layers.Dense(1)\n",
    "                ])\n",
    "                     # Compile the model\n",
    "                    model.compile(optimizer=Adam(0.0009), loss='mse')\n",
    "                     # Train the model\n",
    "                    history = model.fit(\n",
    "                        X_train, y_train,\n",
    "                        epochs=850,\n",
    "                        batch_size=32,\n",
    "                        validation_split=0.1,\n",
    "                        shuffle=False,\n",
    "                        callbacks=[early_stop],  # 添加 EarlyStopping 回调函数\n",
    "                        verbose=0\n",
    "                    )\n",
    "                     # Evaluate the model\n",
    "                    # loss = model.evaluate(X_test, y_test)\n",
    "                    # print(loss)\n",
    "\n",
    "                    # Predict the test values using the trained model\n",
    "                    y_pred = model.predict(X_test)\n",
    "\n",
    "                    # 将 y_pred 和 y_test 逆归一化\n",
    "                    y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "                    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "                    # 计算 MSE\n",
    "                    mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "                    # print(\"MSE: \", mse)\n",
    "                    tot_mse = tf.reduce_sum(mse)\n",
    "                    avg_mse = tot_mse / mse.shape[0]\n",
    "                    print('Test MSE: %.3f' % avg_mse)\n",
    "\n",
    "                    # # 设置x轴标签的格式\n",
    "                    # plt.xticks(rotation=45, ha='right')\n",
    "                    # plt.plot(filtered_df_byday.index[-len(y_test):], y_test, label='Actual')\n",
    "                    # plt.plot(filtered_df_byday.index[-len(y_pred):], y_pred, label='Predicted')\n",
    "                    # plt.title('sales_region_code_' + str(int(sales_region_code)) + ' & ' + 'item_code_' + str(int(item_code))+ '\\nfirst_cate_code_' + str(int(first_cate_code)) + ' & ' + 'second_cate_code_' + str(int(second_cate_code)))\n",
    "                    # plt.legend()\n",
    "                    # plt.show()\n",
    "\n",
    "                    # 预测未来days_to_predict天的订单数量\n",
    "                    days_to_predict_1_month = 30\n",
    "                    days_to_predict_2_month = 60\n",
    "                    days_to_predict_3_month = 90\n",
    "\n",
    "                    # 添加这个函数用于预测未来的订单数量\n",
    "                    def predict_future(model, x_input, days_to_predict):\n",
    "                        future_predictions = []\n",
    "                        for _ in range(days_to_predict):\n",
    "                            # 预测未来一天的订单数量\n",
    "                            predicted_value = model.predict(x_input[np.newaxis, ...])\n",
    "                            # 将预测值添加到future_predictions列表中\n",
    "                            future_predictions.append(predicted_value[0][0])\n",
    "                            # 将x_input中的第一列（订单数量）替换为预测值\n",
    "                            x_input[:, 0] = np.append(x_input[1:, 0], predicted_value)\n",
    "                        return future_predictions\n",
    "\n",
    "                    # 提取最后一个时间窗口的输入数据\n",
    "                    x_input = X_test[-1]\n",
    "                    # print(X_test[-1])\n",
    "                    # print(scaler.inverse_transform(np.array(X_test[-1]).reshape(-1, 1)).flatten())\n",
    "\n",
    "                    # 使用模型进行未来30天的预测\n",
    "                    future_predictions_1_month = predict_future(model, x_input, days_to_predict_1_month)\n",
    "                    print(future_predictions_1_month)\n",
    "                    future_predictions_2_month = predict_future(model, x_input, days_to_predict_2_month)\n",
    "                    future_predictions_3_month = predict_future(model, x_input, days_to_predict_3_month)\n",
    "\n",
    "\n",
    "                    # 将预测结果逆归一化\n",
    "                    future_sum_1_month = sum(scaler.inverse_transform(np.array(future_predictions_1_month).reshape(-1, 1)).flatten())\n",
    "                    future_sum_2_month = sum(scaler.inverse_transform(np.array(future_predictions_2_month).reshape(-1, 1)).flatten()) - future_sum_1_month\n",
    "                    future_sum_3_month = sum(scaler.inverse_transform(np.array(future_predictions_3_month).reshape(-1, 1)).flatten()) - future_sum_2_month - future_sum_1_month\n",
    "\n",
    "\n",
    "                    # 将销售区域代码、物品代码、一级类别代码、二级类别代码以及未来30天的预测值总和追加到predictions_df\n",
    "                    predictions_df = predictions_df.append({\n",
    "                        'sales_region_code': sales_region_code,\n",
    "                        'item_code': item_code,\n",
    "                        'first_cate_code': first_cate_code,\n",
    "                        'second_cate_code': second_cate_code,\n",
    "                        'mse': 0,\n",
    "                        'prediction_1_month': future_sum_1_month,\n",
    "                        'prediction_2_month': future_sum_2_month,\n",
    "                        'prediction_3_month': future_sum_3_month\n",
    "                    }, ignore_index=True)\n",
    "            if test_size == 1:\n",
    "                # 将销售区域代码、物品代码、一级类别代码、二级类别代码以及未来30天的预测值总和追加到predictions_df\n",
    "                predictions_df = predictions_df.append({\n",
    "                    'sales_region_code': sales_region_code,\n",
    "                    'item_code': item_code,\n",
    "                    'first_cate_code': first_cate_code,\n",
    "                    'second_cate_code': second_cate_code,\n",
    "                    'mse': 0,\n",
    "                    'prediction_1_month': test,\n",
    "                    'prediction_2_month': test,\n",
    "                    'prediction_3_month': test\n",
    "                }, ignore_index=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 循环结束后保存predictions_df到新的CSV文件中\n",
    "predictions_df.to_csv(\"predictions-有-4.csv\", index=False, encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
